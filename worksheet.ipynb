{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a968e2bc",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d59d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio.v3 as iio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26780b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "red = cv2.resize(cv2.imread(r'imSeg/red.jpg'),[1200, 675])\n",
    "blue = cv2.resize(cv2.imread(r'imSeg/blue.jpg'),[1200, 675])\n",
    "sarena = cv2.imread(r'imSeg/sarena.jpg')\n",
    "male = cv2.imread(r'imSeg/male.jpg')\n",
    "gcloth = cv2.imread(r'imSeg/gcloth.jpg')\n",
    "hard = cv2.imread(r'imSeg/hard.jpg')\n",
    "test = cv2.imread(r'imSeg/test_trouble.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3724ad8a",
   "metadata": {},
   "source": [
    "## Coler conversion and thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef2caae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hsv_values_from_pixel(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        hsv_image = param['hsv_image']\n",
    "        pixel_hsv = hsv_image[y, x]\n",
    "        print(f\"HSV value at ({x}, {y}): {pixel_hsv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87f0670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hsv_range(image):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    cv2.imshow(\"get HSV\", image)\n",
    "    cv2.setMouseCallback(\"get HSV\", get_hsv_values_from_pixel, {'hsv_image': hsv_image})\n",
    "    cv2.waitKey(2000)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7958be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_segment_image(image):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_green = np.array([28, 30, 50])\n",
    "    upper_green = np.array([42, 256, 256])\n",
    "\n",
    "    mask = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "\n",
    "    segmented_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    return segmented_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3bf9cd",
   "metadata": {},
   "source": [
    "### good image values \n",
    "(lower_green = np.array([30, 60, 130])\n",
    "upper_green = np.array([40, 256, 256]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3784d625",
   "metadata": {},
   "source": [
    "#Good for jannik side:\n",
    "lower_green = np.array([28, 18, 130])\n",
    "    upper_green = np.array([89, 256, 256])\n",
    "\n",
    "    with background: lower_green = np.array([28, 30, 50])\n",
    "    upper_green = np.array([42, 256, 256])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3353806e",
   "metadata": {},
   "source": [
    "## Blurring and canny edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5281f65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_detect(segmented_image):\n",
    "    gray_segmented = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blurred_gray = cv2.GaussianBlur(gray_segmented, (11, 11), 0)\n",
    "\n",
    "    threshold1 = 50\n",
    "    threshold2 = 150\n",
    "\n",
    "    edges = cv2.Canny(blurred_gray, threshold1, threshold2, apertureSize=3)\n",
    "\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "73a27fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.imread(r'reportMedia\\steadyKNN.png')\n",
    "\n",
    "edged = canny_edge_detect(color_segment_image(test))\n",
    "\n",
    "cv2.imshow(\"get HSV\", edged)\n",
    "cv2.waitKey(2000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd14af8",
   "metadata": {},
   "source": [
    "## Hough transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4029c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_tennis_ball_hough(canny_edges_image, original_image):\n",
    "\n",
    "    # Make a copy of the original image to draw on\n",
    "    output_image = original_image.copy()\n",
    "\n",
    "    # quick scaling (dirty but makes detection less resolution dependent)\n",
    "    img_height = output_image.shape[0]\n",
    "\n",
    "    scaling = img_height * 0.001\n",
    "\n",
    "    circles = cv2.HoughCircles(\n",
    "        canny_edges_image,\n",
    "        cv2.HOUGH_GRADIENT,\n",
    "        dp=3,          # Inverse ratio of accumulator resolution (1 for same resolution, 2 for half)\n",
    "        param1=100,      # Upper threshold for the internal Canny edge detector (e.g., 50-200)\n",
    "        param2= 20 * scaling,       # Accumulator threshold for the circle centers. Lower -> more false circles. (e.g., 20-100)\n",
    "        minRadius=3, # Minimum radius of the circles to detect\n",
    "        maxRadius=15,  # Maximum radius of the circles to detect\n",
    "        minDist= 75, # Minimum distance between centers (e.g., about the ball's diameter)\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    detected_ball_info = None\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        # Take the first detected circle for simplicity (you'd add data association here)\n",
    "        i = circles[0, 0]\n",
    "        center_x, center_y, radius = i[0], i[1], i[2]\n",
    "        #cv2.circle(output_image, (center_x, center_y), radius, (0, 0, 200), 2)\n",
    "        #cv2.circle(output_image, (center_x, center_y), 2, (200, 80, 200), 3)\n",
    "        detected_ball_info = (center_x, center_y) # Only returning (x,y) for Kalman measurement\n",
    "    return output_image, detected_ball_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2301a29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HSV value at (730, 144): [33 98 81]\n"
     ]
    }
   ],
   "source": [
    "image = test\n",
    "\n",
    "resize = cv2.resize(image,[1200, 675])\n",
    "\n",
    "segmented_image = color_segment_image(test)\n",
    "\n",
    "#cannyed_image = canny_edge_detect(segmented_image)\n",
    "\n",
    "\n",
    "#output_image, circles = detect_tennis_ball_hough(cannyed_image, image, 7, 50)\n",
    "\n",
    "#print(circles)\n",
    "\n",
    "#tune_hsv_range(image)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow(\"Original Image - Click to get HSV\", segmented_image)\n",
    "cv2.waitKey(2000)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "tune_hsv_range(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cbdbb4",
   "metadata": {},
   "source": [
    "## Kalman filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dfc7a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilterTracker:\n",
    "    def __init__(self):\n",
    "        # Initialize Kalman Filter\n",
    "        # 4 state variables: [x, y, vx, vy]\n",
    "        # 2 measurement variables: [x_measured, y_measured]\n",
    "        self.kf = cv2.KalmanFilter(4, 2)\n",
    "\n",
    "        # Transition Matrix (A) - Constant velocity model\n",
    "        self.kf.transitionMatrix = np.array([[1, 0, 1, 0],\n",
    "                                             [0, 1, 0, 1],\n",
    "                                             [0, 0, 1, 0],\n",
    "                                             [0, 0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "        # Measurement Matrix (H) - We measure position directly\n",
    "        self.kf.measurementMatrix = np.array([[1, 0, 0, 0],\n",
    "                                             [0, 1, 0, 0]], dtype=np.float32)\n",
    "\n",
    "        # Process Noise Covariance (Q) - Tune these!\n",
    "        # Accounts for uncertainty in our model (e.g., ball acceleration)\n",
    "        self.kf.processNoiseCov = np.eye(4, dtype=np.float32) * 0.1 # Example: uniform small noise\n",
    "        # More refined:\n",
    "        # self.kf.processNoiseCov = np.array([[1, 0, 0, 0],   # Noise for x\n",
    "        #                                     [0, 1, 0, 0],   # Noise for y\n",
    "        #                                     [0, 0, 0.05, 0], # Noise for vx\n",
    "        #                                     [0, 0, 0, 0.05]], dtype=np.float32)\n",
    "\n",
    "        # Measurement Noise Covariance (R) - Tune these!\n",
    "        # Accounts for noise in our detection (Hough output jitter)\n",
    "        self.kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * 50 # Example: uniform measurement noise\n",
    "        # More refined:\n",
    "        # self.kf.measurementNoiseCov = np.array([[50, 0],\n",
    "        #                                         [0, 50]], dtype=np.float32)\n",
    "\n",
    "        # Error Covariance (P) - Initial uncertainty in state. Large values are typical.\n",
    "        self.kf.errorCovPost = np.eye(4, dtype=np.float32) * 1000\n",
    "\n",
    "        # Initial state (x,y,vx,vy) - Will be set after first detection\n",
    "        self.kf.statePost = np.zeros((4, 1), dtype=np.float32)\n",
    "\n",
    "        self.is_initialized = False\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Predicts the next state of the tracked object.\n",
    "        Returns: Tuple (predicted_x, predicted_y)\n",
    "        \"\"\"\n",
    "        predicted_state = self.kf.predict()\n",
    "        predicted_x = int(predicted_state[0])\n",
    "        predicted_y = int(predicted_state[1])\n",
    "        return (predicted_x, predicted_y)\n",
    "\n",
    "    def update(self, measurement):\n",
    "        \"\"\"\n",
    "        Updates the Kalman filter with a new measurement.\n",
    "        Args:\n",
    "            measurement (tuple): (x, y) coordinates of the detected object.\n",
    "        Returns: Tuple (estimated_x, estimated_y)\n",
    "        \"\"\"\n",
    "        if not self.is_initialized:\n",
    "            # Initialize state with the first measurement\n",
    "            self.kf.statePost = np.array([[measurement[0]],\n",
    "                                          [measurement[1]],\n",
    "                                          [0.], # Initial vx\n",
    "                                          [0.]], dtype=np.float32) # Initial vy\n",
    "            self.is_initialized = True\n",
    "            # For the very first update, predict and correct are essentially the same as init.\n",
    "            # We can return the measurement itself or run a quick predict/correct.\n",
    "            # For simplicity, let's just use the measurement as the first estimated state.\n",
    "            return measurement[0], measurement[1]\n",
    "        else:\n",
    "            # Create the measurement vector for Kalman filter\n",
    "            np_measurement = np.array([[measurement[0]],\n",
    "                                       [measurement[1]]], dtype=np.float32)\n",
    "\n",
    "            # Correct the state based on the measurement\n",
    "            estimated_state = self.kf.correct(np_measurement)\n",
    "            estimated_x = int(estimated_state[0])\n",
    "            estimated_y = int(estimated_state[1])\n",
    "            return (estimated_x, estimated_y)\n",
    "\n",
    "    def get_current_state(self):\n",
    "        \"\"\"\n",
    "        Returns the current estimated state (x, y, vx, vy).\n",
    "        \"\"\"\n",
    "        return self.kf.statePost.flatten().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b0587",
   "metadata": {},
   "source": [
    "## Video reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e1d517b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_file(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}\")\n",
    "        return\n",
    "\n",
    "    fgbg = cv2.createBackgroundSubtractorKNN(history=8, dist2Threshold=3000, detectShadows=False)\n",
    "\n",
    "    MOGbg = cv2.createBackgroundSubtractorMOG2(history=8, varThreshold=300, detectShadows=False)\n",
    "\n",
    "\n",
    "    # Loop through frames\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.resize(frame,[854, 480])\n",
    "\n",
    "        if not ret:\n",
    "            print(\"End of video stream or error reading frame.\")\n",
    "            break\n",
    "\n",
    "        kalman_tracker = KalmanFilterTracker()\n",
    "\n",
    "        foreground_mask = fgbg.apply(frame)\n",
    "        #MOG_foreground = MOGbg.apply(frame)\n",
    "\n",
    "        segmented_foreground = cv2.bitwise_and(frame, frame, mask=foreground_mask)\n",
    "        #segmented_MOG_foreground = cv2.bitwise_and(frame, frame, mask=MOG_foreground)\n",
    "\n",
    "        color_segemented = color_segment_image(segmented_foreground)\n",
    "\n",
    "        \n",
    "\n",
    "        cannyed_image = canny_edge_detect(color_segemented)\n",
    "        inpainted_hough, detected_ball_pos = detect_tennis_ball_hough(cannyed_image, frame)\n",
    "\n",
    "        # --- Kalman Filter Integration ---\n",
    "        predicted_point = kalman_tracker.predict() # Always predict\n",
    "        cv2.circle(inpainted_hough, predicted_point, 5, (0, 0, 255), -1) # Red for prediction\n",
    "        cv2.putText(inpainted_hough, \"Predicted\", (predicted_point[0] + 10, predicted_point[1] - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        if detected_ball_pos:\n",
    "            # If a detection is found, update the Kalman filter\n",
    "            estimated_x, estimated_y = kalman_tracker.update(detected_ball_pos)\n",
    "            # Draw corrected point (blue circle)\n",
    "            cv2.circle(inpainted_hough, (estimated_x, estimated_y), 5, (255, 0, 0), -1)\n",
    "            cv2.putText(inpainted_hough, \"Estimated\", (estimated_x + 10, estimated_y + 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        else:\n",
    "            # If no detection, the filter relies purely on its prediction\n",
    "            print(f\"No detection in frame {cap.get(cv2.CAP_PROP_POS_FRAMES)}, relying on prediction.\")\n",
    "\n",
    "\n",
    "        cv2.imshow('Video Feed (Original)', segmented_foreground)\n",
    "        cv2.imshow('Video Feed (Grayscale)', frame)\n",
    "        cv2.imshow('Video Feed (frame)', inpainted_hough) \n",
    "        #print(circles)\n",
    "\n",
    "        # increase waitkey value for fewer frames per second\n",
    "        if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "            print(\"Exiting video display.\")\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7e99458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lizzy\\AppData\\Local\\Temp\\ipykernel_13940\\2316264213.py:48: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predicted_x = int(predicted_state[0])\n",
      "C:\\Users\\lizzy\\AppData\\Local\\Temp\\ipykernel_13940\\2316264213.py:49: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predicted_y = int(predicted_state[1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting video display.\n"
     ]
    }
   ],
   "source": [
    "Jannik_side_view_480p_trim = cv2.VideoCapture(r'vidSeg/Jannik_side_view_480p_trim.mp4')\n",
    "Back_view_720p_trim = cv2.VideoCapture(r'vidSeg/Back_view_720p_trim.mp4')\n",
    "\n",
    "process_video_file(r'vidSeg/close_trim.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e12f45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
