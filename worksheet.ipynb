{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a968e2bc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53d59d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio.v3 as iio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3724ad8a",
   "metadata": {},
   "source": [
    "## Coler conversion and thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef2caae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hsv_values_from_pixel(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        hsv_image = param['hsv_image']\n",
    "        pixel_hsv = hsv_image[y, x]\n",
    "        print(f\"HSV value at ({x}, {y}): {pixel_hsv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e87f0670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hsv_range(image):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    cv2.imshow(\"get HSV\", image)\n",
    "    cv2.setMouseCallback(\"get HSV\", get_hsv_values_from_pixel, {'hsv_image': hsv_image})\n",
    "    cv2.waitKey(2000)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7958be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_segment_image(image):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_green = np.array([28, 30, 50])\n",
    "    upper_green = np.array([42, 256, 256])\n",
    "\n",
    "    mask = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "\n",
    "    segmented_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    return segmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5281f65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_detect(segmented_image):\n",
    "    gray_segmented = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blurred_gray = cv2.GaussianBlur(gray_segmented, (11, 11), 0)\n",
    "\n",
    "    threshold1 = 50\n",
    "    threshold2 = 150\n",
    "\n",
    "    edges = cv2.Canny(blurred_gray, threshold1, threshold2, apertureSize=3)\n",
    "\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a27fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.imread(r'reportMedia\\steadyKNN.png')\n",
    "\n",
    "edged = canny_edge_detect(color_segment_image(test))\n",
    "\n",
    "cv2.imshow(\"get HSV\", edged)\n",
    "cv2.waitKey(2000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd14af8",
   "metadata": {},
   "source": [
    "## Hough transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4029c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_tennis_ball_hough(canny_edges_image, original_image):\n",
    "\n",
    "    output_image = original_image.copy()\n",
    "\n",
    "    # quick scaling (dirty but makes detection less resolution dependent)\n",
    "    img_height = output_image.shape[0]\n",
    "\n",
    "    scaling = img_height * 0.001\n",
    "\n",
    "    circles = cv2.HoughCircles(\n",
    "        canny_edges_image,\n",
    "        cv2.HOUGH_GRADIENT,\n",
    "        dp=3,          # accumulator resolution\n",
    "        param1=100,      # Upper threshold for the internal Canny edge detector\n",
    "        param2= 20 * scaling,       # Accumulator threshold\n",
    "        minRadius=3, # Minimum radius\n",
    "        maxRadius=15,  # Maximum radius\n",
    "        minDist= 75, # Minimum distance between centers\n",
    "    )\n",
    "\n",
    "    detected_circles = []\n",
    "\n",
    "    # Draw detected circles\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        for i in circles[0, :]:\n",
    "            center_x, center_y, radius = i[0], i[1], i[2]\n",
    "            detected_circles.append((center_x, center_y, radius))\n",
    "\n",
    "            # inpaint of detected tennis ball\n",
    "            cv2.circle(output_image, (center_x, center_y), radius, (0, 0, 200), 2)\n",
    "            cv2.circle(output_image, (center_x, center_y), 1, (200, 80, 200), 3)\n",
    "\n",
    "    return output_image, detected_circles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd511e6",
   "metadata": {},
   "source": [
    "## Image testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2301a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "red = cv2.resize(cv2.imread(r'imSeg/red.jpg'),[1200, 675])\n",
    "blue = cv2.resize(cv2.imread(r'imSeg/blue.jpg'),[1200, 675])\n",
    "sarena = cv2.imread(r'imSeg/sarena.jpg')\n",
    "male = cv2.imread(r'imSeg/male.jpg')\n",
    "gcloth = cv2.imread(r'imSeg/gcloth.jpg')\n",
    "hard = cv2.imread(r'imSeg/hard.jpg')\n",
    "test = cv2.imread(r'imSeg/test_trouble.jpg')\n",
    "\n",
    "image = test\n",
    "\n",
    "resize = cv2.resize(image,[1200, 675])\n",
    "\n",
    "segmented_image = color_segment_image(test)\n",
    "\n",
    "#cannyed_image = canny_edge_detect(segmented_image)\n",
    "\n",
    "\n",
    "#output_image, circles = detect_tennis_ball_hough(cannyed_image, image, 7, 50)\n",
    "\n",
    "#print(circles)\n",
    "\n",
    "#tune_hsv_range(image)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow(\"Original Image - Click to get HSV\", segmented_image)\n",
    "cv2.waitKey(2000)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "tune_hsv_range(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cbdbb4",
   "metadata": {},
   "source": [
    "## Kalman filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfc7a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE WHOLE OF THE KalmanFilterTracker CLASS WAS ASSISTED WITH GOOGLE GEMINI\n",
    "class KalmanFilterTracker:\n",
    "    def __init__(self):\n",
    "        # Initialize Kalman Filter\n",
    "        # 4 state variables: [x, y, vx, vy]\n",
    "        # 2 measurement variables: [x_measured, y_measured]\n",
    "        self.kf = cv2.KalmanFilter(4, 2, 2)\n",
    "\n",
    "        # Transition Matrix (A) - Constant velocity model\n",
    "        self.kf.transitionMatrix = np.array([[1, 0, 1, 0],\n",
    "                                             [0, 1, 0, 1],\n",
    "                                             [0, 0, 1, 0],\n",
    "                                             [0, 0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "        # Measurement Matrix (H) - We measure position directly\n",
    "        self.kf.measurementMatrix = np.array([[1, 0, 0, 0],\n",
    "                                             [0, 1, 0, 0]], dtype=np.float32)\n",
    "\n",
    "        GRAVITY_ACCEL_Y_PIXELS_PER_FRAME_SQ = 1\n",
    "\n",
    "        self.kf.controlMatrix = np.array([[0.5, 0],   # Affects x position (0.5 * ax * dt^2)\n",
    "                                          [0, 0.5],   # Affects y position (0.5 * ay * dt^2)\n",
    "                                          [1, 0],     # Affects vx (ax * dt)\n",
    "                                          [0, 1]], dtype=np.float32) # Affects vy (ay * dt)\n",
    "\n",
    "        # The actual control input vector (u_k) - [ax_control, ay_control]\n",
    "        # For pure gravity, ax_control is 0, ay_control is your gravity constant.\n",
    "        self.gravity_control_vector = np.array([[0],\n",
    "                                                [GRAVITY_ACCEL_Y_PIXELS_PER_FRAME_SQ]], dtype=np.float32)\n",
    "\n",
    "        # Process Noise Covariance (Q) - Tune these!\n",
    "        # Accounts for uncertainty in our model (e.g., ball acceleration)\n",
    "        #self.kf.processNoiseCov = np.eye(4, dtype=np.float32) * 0.1 # Example: uniform small noise\n",
    "        # More refined:\n",
    "        self.kf.processNoiseCov = np.array([[0.1, 0, 0, 0],   # Noise for x\n",
    "                                            [0, 0.1, 0, 0],   # Noise for y\n",
    "                                            [0, 0, 1, 0], # Noise for vx\n",
    "                                            [0, 0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "        # Measurement Noise Covariance (R) - Tune these!\n",
    "        # Accounts for noise in our detection (Hough output jitter)\n",
    "        self.kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * 0.2 # Example: uniform measurement noise\n",
    "        # More refined:\n",
    "        # self.kf.measurementNoiseCov = np.array([[50, 0],\n",
    "        #                                         [0, 50]], dtype=np.float32)\n",
    "\n",
    "        # Error Covariance (P) - Initial uncertainty in state. Large values are typical.\n",
    "        self.kf.errorCovPost = np.eye(4, dtype=np.float32) * 1000\n",
    "\n",
    "        # Initial state (x,y,vx,vy) - Will be set after first detection\n",
    "        self.kf.statePost = np.zeros((4, 1), dtype=np.float32)\n",
    "\n",
    "        self.is_initialized = False\n",
    "\n",
    "    def predict(self):\n",
    "\n",
    "        predicted_state = self.kf.predict(self.gravity_control_vector)\n",
    "        predicted_x = int(predicted_state[0])\n",
    "        predicted_y = int(predicted_state[1])\n",
    "        return (predicted_x, predicted_y)\n",
    "\n",
    "    def update(self, measurement):\n",
    "        if not self.is_initialized:\n",
    "            # Initialize state with the first measurement\n",
    "            self.kf.statePost = np.array([[measurement[0]],\n",
    "                                          [measurement[1]],\n",
    "                                          [0.], # Initial vx\n",
    "                                          [0.]], dtype=np.float32) # Initial vy\n",
    "            self.is_initialized = True\n",
    "            # For the very first update, predict and correct are essentially the same as init.\n",
    "            # We can return the measurement itself or run a quick predict/correct.\n",
    "            # For simplicity, let's just use the measurement as the first estimated state.\n",
    "            return measurement[0], measurement[1]\n",
    "        else:\n",
    "            # Create the measurement vector for Kalman filter\n",
    "            np_measurement = np.array([[measurement[0]],\n",
    "                                       [measurement[1]]], dtype=np.float32)\n",
    "\n",
    "            # Correct the state based on the measurement\n",
    "            estimated_state = self.kf.correct(np_measurement)\n",
    "            estimated_x = int(estimated_state[0])\n",
    "            estimated_y = int(estimated_state[1])\n",
    "            return (estimated_x, estimated_y)\n",
    "\n",
    "    def get_current_state(self):\n",
    "        \"\"\"\n",
    "        Returns the current estimated state (x, y, vx, vy).\n",
    "        \"\"\"\n",
    "        return self.kf.statePost.flatten().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b0587",
   "metadata": {},
   "source": [
    "## Video reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1d517b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_file(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}\")\n",
    "        return\n",
    "\n",
    "    fgbg = cv2.createBackgroundSubtractorKNN(history=8, dist2Threshold=3000, detectShadows=False)\n",
    "\n",
    "    #MOGbg = cv2.createBackgroundSubtractorMOG2(history=8, varThreshold=300, detectShadows=False)\n",
    "\n",
    "    #kalman_tracker = KalmanFilterTracker()\n",
    "\n",
    "    arr = []\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate target frame count for 10 seconds\n",
    "    target_frames = int(fps * 10)\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    # Loop through frames\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.resize(frame,[854, 480])\n",
    "\n",
    "        if not ret:\n",
    "            print(\"End of video stream or error reading frame.\")\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        \n",
    "\n",
    "        if frame_count > target_frames:\n",
    "            print(f\"Reached {frame_count} frames, stopping after 10 seconds.\")\n",
    "            break\n",
    "\n",
    "        foreground_mask = fgbg.apply(frame)\n",
    "        #MOG_foreground = MOGbg.apply(frame)\n",
    "\n",
    "        segmented_foreground = cv2.bitwise_and(frame, frame, mask=foreground_mask)\n",
    "        #segmented_MOG_foreground = cv2.bitwise_and(frame, frame, mask=MOG_foreground)\n",
    "\n",
    "        color_segemented = color_segment_image(segmented_foreground)\n",
    "\n",
    "        \n",
    "\n",
    "        cannyed_image = canny_edge_detect(color_segemented)\n",
    "        inpainted_hough, detected_ball_pos = detect_tennis_ball_hough(cannyed_image, frame)\n",
    "\n",
    "        #print(len(detected_ball_pos))\n",
    "\n",
    "        ## --- Kalman Filter Integration --- AI ASSISTED\n",
    "        #predicted_point = kalman_tracker.predict() # Always predict\n",
    "        #cv2.circle(inpainted_hough, predicted_point, 2, (0, 0, 255), -1) # Red for prediction\n",
    "        #cv2.putText(inpainted_hough, \"Predicted\", (predicted_point[0] + 10, predicted_point[1] - 10),\n",
    "        #            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        #if detected_ball_pos:\n",
    "        #    # If a detection is found, update the Kalman filter\n",
    "        #    estimated_x, estimated_y = kalman_tracker.update(detected_ball_pos)\n",
    "        #    # Draw corrected point (blue circle)\n",
    "        #    cv2.circle(inpainted_hough, (estimated_x, estimated_y), 2, (255, 0, 0), -1)\n",
    "        #    cv2.putText(inpainted_hough, \"Estimated\", (estimated_x + 10, estimated_y + 10),\n",
    "        #                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        #else:\n",
    "        #    # If no detection, the filter relies purely on its prediction\n",
    "        #    print(f\"No detection in frame {cap.get(cv2.CAP_PROP_POS_FRAMES)}, relying on prediction.\")\n",
    "\n",
    "\n",
    "        cv2.imshow('Original footage', frame)\n",
    "        cv2.imshow('Background segment', segmented_foreground)\n",
    "        cv2.imshow('Background + color segment', color_segemented)\n",
    "        cv2.imshow('Inpainted detection of original', inpainted_hough) \n",
    "\n",
    "        # increase waitkey value for fewer frames per second\n",
    "        if cv2.waitKey(50) & 0xFF == ord('w'):\n",
    "            print(\"skipping\")\n",
    "            break\n",
    "        #elif cv2.waitKey(800) & 0xFF == ord('q'):\n",
    "        #    print(\"Exiting\")\n",
    "        #    break\n",
    "\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e99458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping\n"
     ]
    }
   ],
   "source": [
    "#Jannik_side_view_480p_trim = cv2.VideoCapture(r'vidSeg/Jannik_side_view_480p_trim.mp4')\n",
    "#Back_view_720p_trim = cv2.VideoCapture(r'vidSeg/Back_view_720p_trim.mp4')\n",
    "\n",
    "process_video_file(r'vidSeg/close_trim.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
